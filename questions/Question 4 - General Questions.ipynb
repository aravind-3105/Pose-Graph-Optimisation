{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mexican-confirmation",
   "metadata": {},
   "source": [
    "# Question 4: General Theory/Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-cleaners",
   "metadata": {},
   "source": [
    "_No need to be verbose, it's not fun for anyone_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-hindu",
   "metadata": {},
   "source": [
    "1. What part of S**L**A**M** did this project deal with? Why? What does the other part deal with and how would it generally work, given that you only have LIDAR scans, RGB video stream, and noisy pose data for a moving robot?\n",
    "\n",
    "\n",
    "2. Loop closures play an important role in reducing drift, how would you go about detecting these?\n",
    "\n",
    "\n",
    "3. Explain the structure of your Jacobian. Is the pose-graph fully connected? Why/Why not?\n",
    "\n",
    "\n",
    "4. With what you know now, how would you describe and differentiate the SLAM frontend and backend? Why do we need to optimise our poses/map in the first place - where does the noise come from/why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-bones",
   "metadata": {},
   "source": [
    "_Your Answer_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c619337-fa0d-41ed-bc6d-7cf220435a54",
   "metadata": {},
   "source": [
    "## Answer 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a90787-b216-45ab-912e-293bfa90bfcf",
   "metadata": {},
   "source": [
    "This project essentially deals with the **localisation** of SLAM. We only try to navigate in an unknown environment based on the odometry provided and the loop closure, control constraints. But there is not component that deals with the **mapping aspect** i.e. actually building the map of unknown environment.<br> \n",
    "Another aspect of comparison can be that we essentially only deal with the **backend** of SLAM and not the fornt-end. We are involved only in the processing of constrains(control, loop-closure), trajectory while not dealing with the front-ends aspects like feature adjustment, odometry, data association etc.<br>\n",
    "Given that we have LiDAR scans, RGB video stream and noisy pose data; for the first comparison, building the map would involve state estimation, prediction and observation of landmarks using the sensor data. The mapping part will try to optimize the transforms of the point clouds given the landmark information obtained from the sensors? As the data is noisy, on multiple iterations this will be improved. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6312293-69a7-4b34-9e02-338f74f60c8b",
   "metadata": {},
   "source": [
    "## Answer 2\n",
    "Loop closures are used to compensate for drift. Once the loop closures are properly found, it's used to backtrack drift errors caused in the SLAM implementation. It can be identified using NNs like PLce Net, Net VLAD can be used for detecting these. They are also performed by the global descriptor matching or Likelihood composition using SIFT etc. In a more intuitive sense, we can have two broad possiblities:geometric and feature based.<br>\n",
    "    i)Geometry Based: It involved using the odometer to actually detect if a certain position has been passed before and identiying loop(not efficient and accruate enough due to errors).<br>\n",
    "    ii)Feature Based: It involves similarity between two frames of images for detection which(error wont influence like the geometric case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050f93e2-0996-451c-9bd8-316d31774ed5",
   "metadata": {},
   "source": [
    "## Answer 3\n",
    "The jacobian columns contains the partial derivative of the residual with respect to poses $x_i, y_i, theta_i$ where i spans over all vertices\n",
    "\n",
    "$J = \\begin{bmatrix}\n",
    "    \\frac{\\partial f}{\\partial x_{0}} \\frac{\\partial f}{\\partial y_{0}} \\frac{\\partial f}{\\partial \\theta_{0}} \\dots \\frac{\\partial f}{\\partial x_{v}} \\frac{\\partial f}{\\partial y_{v}} \\frac{\\partial f}{\\partial \\theta_{v}}\\\\\n",
    "    \\end{bmatrix}$\n",
    "    \n",
    "where \n",
    "\n",
    "$f = \\begin{bmatrix}\n",
    "    x_{0} + \\Delta x_{(0,1)} \\cos(\\theta_0) - \\Delta y_{(0,1)} \\sin(\\theta_0) - x_{1}\\\\\n",
    "    y_{0} + \\Delta y_{(0,1)} \\cos(\\theta_0) + \\Delta x_{(0,1)} \\sin(\\theta_0) - y_{1}  \\\\\n",
    "    \\theta_{0}+  \\Delta \\theta_{(0,1)} -  \\theta_{1} \\\\\n",
    "    \\vdots \\\\\n",
    "    x_{p-1} + \\Delta x_{(p-1,p)} \\cos(\\theta_{p-1}) - \\Delta y_{(p-1,p)} \\sin(\\theta_{p-1}) - x_{p}\\\\\n",
    "    y_{p-1} + \\Delta y_{(p-1,p)} \\cos(\\theta_{p-1}) + \\Delta x_{(p-1,p)} \\sin(\\theta_{p-1}) - y_{p}  \\\\\n",
    "    \\theta_{p-1}+  \\Delta \\theta_{(p-1,p)} -  \\theta_{p} \\\\\n",
    "x_{l[0]}+\\Delta x_{(l[0],l[1])}\\cos(\\theta_{l[0]})-\\Delta y_{(l[0],l[1])}\\sin(\\theta_{l[0]})-x_{l[1]}\\\\\n",
    "y_{l[0]}+\\Delta y_{(l[0],l[1])}\\cos(\\theta_{l[0]})+\\Delta x_{(l[0],l[1])}\\sin(\\theta_{l[0]})-y_{l[1]}\\\\\n",
    "    \\theta_{l[0]}+  \\Delta \\theta_{(l[0],l[1])} -  \\theta_{l[1]} \\\\\n",
    "    \\vdots \\\\\n",
    "x_{l[q-1]}+\\Delta x_{(l[q-1],l[q])}\\cos(\\theta_{l[q-1]})-\\Delta y_{(l[q-1],l[q])} \\sin(\\theta_{l[q-1]}) - x_{l[q]}\\\\\n",
    "    y_{l[q-1]} + \\Delta y_{(l[q-1],l[q])} \\cos(\\theta_{l[q-1]}) + \\Delta x_{(l[q-1],l[q])} \\sin(\\theta_{l[q-1]}) - y_{l[q]}  \\\\\n",
    "    \\theta_{l[q-1]}+  \\Delta \\theta_{(l[q-1],l[q])} -  \\theta_{l[q]} \\\\\n",
    "    x_{0}  - a\\\\\n",
    "    y_{0} - b  \\\\\n",
    "    \\theta_{0} -  c \\\\\n",
    "    \\end{bmatrix}$\n",
    "\n",
    "The shape of the jacobian is (3p + 3q + 3) X v v is number of vertices, p is number of odometry constraints, q is number of loop constraints.\n",
    "\n",
    "The pose graph **is not fully connected**. This is because odometry edges only connect adjacent vertices and there are only a few (20 to be exact) loop closure edges that connect certain vertices. There exist many vertices that are not connected to each other (for example vertex 0 and vertex 3). This is the case with most SLAM problems(sparsity of SLAM).\n",
    "\n",
    "For a fully connected graph there would have ** $n*(n-1)/2$ ** constrants/edges where n is the number of vertices. We see that there aren't that many constraints in our given problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38dbbb9-9a55-468b-9f61-59ca3fd8140a",
   "metadata": {},
   "source": [
    "## Answer 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b340a7-bd7b-4c3a-b27a-f86c20b03d02",
   "metadata": {},
   "source": [
    "**SLAM front end deals with feature extraction and data association.** It takes the sensor data and gives a set of features for our robot (eg. x,y,theta). Also through sensor information, it gives us odometry and loop closure edges, which is data association between each pose of the robot.  \n",
    "\n",
    "**SLAM back end deals with localization and mapping**. It takes the poses and associations given by the front end and optimizes localization and mapping for our robot.\n",
    "\n",
    "We need to optimise poses/map because the *different data associations given by the SLAM frontend are not always correct. The odometry edges and the loop closure edges have **different susceptibility to Noise**. This leads to conflicting information. If we construct our poses only following the odometry constraints, then the loop closure constraints are often broken. Hence we need to get a balance between following both these constraints and the anchor (fixing the coordinate frame) given. This is why optimisation is important.\n",
    "\n",
    "Noise comes from various sources. One possibility is through sensor readings which are not always accurate. We know that when we are finding the pose of the robot through successive transformations, when it is moving, the error accumulates and the poses are no longer correct. There might also be slight error in loop closure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
