{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "exposed-little",
   "metadata": {},
   "source": [
    "# Question 3: Trajectory Evaluation and g2o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-bachelor",
   "metadata": {},
   "source": [
    "_Refer to the example notebooks for installation instructions_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-atlantic",
   "metadata": {},
   "source": [
    "# Evo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-booking",
   "metadata": {},
   "source": [
    "So you've implemented 2D SLAM, great! Now, what? We need a measure of how good the trajectory is. The error/loss used earlier doesn't tell us much about how the trajectory differs from the ground truth. Here, we try to do just this - compute error metrics. Rather than computing these from scratch, we will just Evo - https://github.com/MichaelGrupp/evo/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-command",
   "metadata": {},
   "source": [
    "Look at the absolute pose error (APE) and relative pose error (RPE). What do they capture and how are they calculated (descriptive answer)? How do these metrics differ in methodology? Can we determine if the error is more along the x/y axis?\n",
    "\n",
    "Answer the above questions and report errors for the obtained trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89396acb-f586-4407-b1f2-4750241f49a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(640x480)\n",
      "saved 'final.kitti' from 'final.g2o'\n",
      "Figure(640x480)\n",
      "saved 'gt.kitti' from '../data/gt.g2o'\n"
     ]
    }
   ],
   "source": [
    "!python3 '../misc/g2o_to_kitti.py' 'final.g2o' 'final.kitti'\n",
    "!python3 '../misc/g2o_to_kitti.py' '../data/gt.g2o' 'gt.kitti'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75eb9cc2-e732-4da4-a8df-6bf5a49d486a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Loaded 120 poses from: gt.kitti\n",
      "Loaded 120 poses from: final.kitti\n",
      "--------------------------------------------------------------------------------\n",
      "Aligning using Umeyama's method...\n",
      "Rotation of alignment:\n",
      "[[ 0.49271096  0.87019303  0.        ]\n",
      " [-0.87019303  0.49271096  0.        ]\n",
      " [ 0.          0.          1.        ]]\n",
      "Translation of alignment:\n",
      "[-6.22104898 -5.02419814  0.        ]\n",
      "Scale correction: 1.0\n",
      "--------------------------------------------------------------------------------\n",
      "Found 119 pairs with delta 1 (frames) among 120 poses using consecutive pairs.\n",
      "Compared 119 relative pose pairs, delta = 1 (frames) with consecutive pairs.\n",
      "Calculating RPE for translation part pose relation...\n",
      "--------------------------------------------------------------------------------\n",
      "RPE w.r.t. translation part (m)\n",
      "for delta = 1 (frames) using consecutive pairs\n",
      "(with SE(3) Umeyama alignment)\n",
      "\n",
      "       max\t0.287004\n",
      "      mean\t0.117269\n",
      "    median\t0.113959\n",
      "       min\t0.005651\n",
      "      rmse\t0.132103\n",
      "       sse\t2.076697\n",
      "       std\t0.060821\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Plotting results... \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!evo_rpe kitti gt.kitti final.kitti -v --plot --plot_mode xy --align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c09c8af6-4239-4596-b84b-d92fec938e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Loaded 120 poses from: gt.kitti\n",
      "Loaded 120 poses from: final.kitti\n",
      "--------------------------------------------------------------------------------\n",
      "Aligning using Umeyama's method...\n",
      "Rotation of alignment:\n",
      "[[ 0.49271096  0.87019303  0.        ]\n",
      " [-0.87019303  0.49271096  0.        ]\n",
      " [ 0.          0.          1.        ]]\n",
      "Translation of alignment:\n",
      "[-6.22104898 -5.02419814  0.        ]\n",
      "Scale correction: 1.0\n",
      "--------------------------------------------------------------------------------\n",
      "Compared 120 absolute pose pairs.\n",
      "Calculating APE for translation part pose relation...\n",
      "--------------------------------------------------------------------------------\n",
      "APE w.r.t. translation part (m)\n",
      "(with SE(3) Umeyama alignment)\n",
      "\n",
      "       max\t6.576558\n",
      "      mean\t1.946908\n",
      "    median\t1.486339\n",
      "       min\t0.299334\n",
      "      rmse\t2.568357\n",
      "       sse\t791.574617\n",
      "       std\t1.675113\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Plotting results... \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! evo_ape kitti gt.kitti final.kitti -v --plot --plot_mode xy --align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d51c77c1-95ac-4e35-af93-e3df3a8955dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Loaded 120 poses from: gt.kitti\n",
      "Loaded 120 poses from: final.kitti\n",
      "--------------------------------------------------------------------------------\n",
      "name:\tgt\n",
      "infos:\n",
      "\tnr. of poses\t120\n",
      "\tpath length (m)\t52.976517997999295\n",
      "\tpos_end (m)\t[-2.8 -4.5  0. ]\n",
      "\tpos_start (m)\t[-8.  5.  0.]\n",
      "--------------------------------------------------------------------------------\n",
      "name:\tfinal\n",
      "infos:\n",
      "\tnr. of poses\t120\n",
      "\tpath length (m)\t53.76229904953299\n",
      "\tpos_end (m)\t[-0.15219536  4.00971174  0.        ]\n",
      "\tpos_start (m)\t[-8.  5.  0.]\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!evo_traj kitti gt.kitti final.kitti -v --plot --plot_mode xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e11f8e6d-706d-4cbd-9c05-4351c2fa3c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPE w.r.t. rotation angle in degrees (deg)\n",
      "for delta = 1.0 (m) using consecutive pairs\n",
      "(not aligned)\n",
      "\n",
      "       max\t42.679308\n",
      "      mean\t12.709113\n",
      "    median\t11.086966\n",
      "       min\t0.811973\n",
      "      rmse\t16.127463\n",
      "       sse\t10663.897293\n",
      "       std\t9.928419\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!evo_rpe kitti gt.kitti final.kitti --pose_relation angle_deg --delta 1 --delta_unit m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94ba913-a1bc-4e4d-9040-7f4966558693",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f762f35-4d26-41bc-aa5b-50f4c0ddfc16",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"../assets/RPE_Error.png\" style=\"width: 350px;\"/> </td>\n",
    "<td> <img src=\"../assets/RPE_Map.png\" style=\"width: 350px;\"/> </td>\n",
    "</tr></table>\n",
    "<table><tr>\n",
    "<td> <img src=\"../assets/APE_Error.png\" style=\"width: 350px;\"/> </td>\n",
    "<td> <img src=\"../assets/APE_MapN.png\" style=\"width: 350px;\"/> </td>\n",
    "</tr></table>\n",
    "<table><tr>\n",
    "<td> <img src=\"../assets/Traj.png\" style=\"width: 350px;\"/> </td></tr><tr>\n",
    "<td> <img src=\"../assets/Traj_XYZ.png\" style=\"width: 350px;\"/> </td></tr><tr>\n",
    "<td> <img src=\"../assets/Trajjj.png\" style=\"width: 350px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-anderson",
   "metadata": {},
   "source": [
    "If you're interested, play around with this tool and add any other plots that you think might be relevant/interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6981f1-cd72-41db-8c3d-b67827673dd8",
   "metadata": {},
   "source": [
    "### Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02caae8f-7038-4052-9578-70be224c2028",
   "metadata": {},
   "source": [
    "1. APE refers to the Absolute Pose Error which refers to the absolute error in the trajectory. The respective corresponding poses of the reference and the estimated trajcetory are compared with. This is repeaed for the entire trajectory and can be seen in the graph as well. It roughly captures the absolute differences which is why the right-side part of the graph that is at a higher distance is having more error thereby giving a global picture of comparison. \n",
    "2. RPE refers to the Relative Pose Error wgich as the name suggests, captures the relative pose errors i.e motion and drift. We can also identify the rotational and translational drift using --pose-relation<br>\n",
    "Yes we can say if error is more along x or y axis based on visual observation of the x,y axis trajectory generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-charity",
   "metadata": {},
   "source": [
    "# g2o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-hayes",
   "metadata": {},
   "source": [
    "Install g2o as mentioned in `examples/g2o.ipynb` and optimise `edges.txt`, the file you used earlier. Also use `g2o_viewer` and optimize `intel` (a trajectory in the Intel research lab) and `sphere`. They should look something like:\n",
    "\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"../misc/intel.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "<td> <img src=\"../misc/sphere.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-football",
   "metadata": {},
   "source": [
    "Write briefly about your observations and try out few options in the GUI. What do they do, how do they perform?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00c6fbc-58b8-466b-91c5-7e7bac3b09ec",
   "metadata": {},
   "source": [
    "## <b>Answers</b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2f657b-1c60-47a9-9a92-584946ad719f",
   "metadata": {},
   "source": [
    "### Optimising edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d84eb2-4726-4593-9b08-cc7303fef140",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"../assets/edges_gt.png\" style=\"width: 350px;\"/> </td>\n",
    "<td> <img src=\"../assets/edges_initialGuess.png\" style=\"width: 350px;\"/> </td>\n",
    "<td><img src=\"../assets/edges_Reload.png\" style=\"width: 350px;\"/> </td></td>\n",
    "</tr></table>\n",
    "<table><tr>\n",
    "<td> <img src=\"../assets/edges_lmvar_huber_620.png\" style=\"width: 350px;\"/> </td>\n",
    "<td> <img src=\"../assets/edges_gnvar_8.png\" style=\"width: 350px;\"/> </td>\n",
    "<td> <img src=\"../assets/edges_lm32_cauchy_100.png\" style=\"width: 350px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c25dbd0-3ecf-423c-84bf-301a25cd4d69",
   "metadata": {},
   "source": [
    "### Optimising intel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a557d4fd-4dfd-4c93-a644-d0d7cd24a293",
   "metadata": {},
   "source": [
    "<!-- ![image.png](../assets/initialIntelg2o.png)\n",
    "![image.png](../assets/intel_gnvar.png)\n",
    "![image.png](../assets/intel_lm32_cauchy.png)\n",
    "![image.png](../assets/intel_lm32_huber.png)\n",
    "![image.png](../assets/intel_lmfix32_700.png) -->\n",
    "<table><tr>\n",
    "<td> <img src=\"../assets/initialIntelg2o.png\" alt=\"Drawing\" style=\"width: 350px;\"/> </td>\n",
    "<td> <img src=\"../assets/intel_gnvar.png\" alt=\"Drawing\" style=\"width: 350px;\"/> </td>\n",
    "</tr></table>\n",
    "<table><tr>\n",
    "<td> <img src=\"../assets/intel_lm32_cauchy.png\" alt=\"Drawing\" style=\"width: 350px;\"/> </td>\n",
    "<td> <img src=\"../assets/intel_lm32_huber.png\" alt=\"Drawing\" style=\"width: 350px;\"/> </td>\n",
    "<td> <img src=\"../assets/intel_lmfix32_700.png\" alt=\"Drawing\" style=\"width: 350px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8032710a-75ab-47f3-8118-a0babf61ac66",
   "metadata": {},
   "source": [
    "### Optimising sphere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c84480c-5e41-4278-aeae-e87a2c0bec8b",
   "metadata": {},
   "source": [
    "<!-- ![image.png](../assets/sphere_initial.png)\n",
    "![image.png](../assets/sphere_lm63_200.png)\n",
    "![image.png](../assets/sphere_lmVar_100.png) -->\n",
    "<table><tr>\n",
    "<td> <img src=\"../assets/sphere_initial.png\"  style=\"width: 350px;\"/> \n",
    "<img src=\"../assets/sphere_lm63_200.png\"  style=\"width: 350px;\"/>\n",
    "<img src=\"../assets/sphere_lmVar_100.png\"  style=\"width: 350px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc94629c-c309-41b5-b8d1-8ca8997699ca",
   "metadata": {},
   "source": [
    "## Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74413b94-deb4-46e4-ad12-45c9fd7d0f6e",
   "metadata": {},
   "source": [
    "The optimisations were done with different optimisers such as LM, GD for different iterations and also by adding Cauchy and Hober kernels. Based on the number optimisers, kernel choices used, we get different number of iterations needed for error to converge and achieve best output. \"Best method\" is also identified based on considering both iterations and min.Error at the end.\n",
    "Best method used for fastest and least error output:\n",
    "1. noisy edge file: lm_fix_3_2_mod with 70 iterations\n",
    "2. intel.g2o file: lm_fix_3_2_mod with 600 iterations along with a Cauchy Robust Kernel\n",
    "3. sphere.g2o file: lm_fix_6_3_mod with 600 iterations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
